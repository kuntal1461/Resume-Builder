# Job Recommendation Scraper - Project Summary
> **Current Status**: Core API Only (Python/FastAPI)

## ğŸ—ï¸ Architecture

The project is now a focused **Python-based Scraping Microservice** that integrates with your existing infrastructure.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Existing Infrastructure      â”‚
â”‚   (MySQL, Redis, etc.)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Scraper Core  â”‚
           â”‚ API (FastAPI) â”‚
           â”‚ Port: 8200    â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Celery Worker â”‚
           â”‚ (Async Jobs)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Components

### 1. **Core (Python)**
- **Framework**: FastAPI
- **Task Queue**: Celery + Redis
- **Database**: SQLAlchemy (MySQL)
- **Scrapers**: Requests, Selenium, Playwright
- **Structure**:
    - `core/entity/`: Database Models
    - `core/repository/`: Data Access
    - `core/service/`: Business Logic
    - `core/enums/`: Enumerations
    - `core/constants/`: Configuration Constants

### 2. **Frontend**
- *Empty directory reserved for future use.*

## ğŸš€ How to Run

```bash
# Start the scraper service
docker-compose up -d scraper-core scraper-worker redis
```

## ğŸ”— API Endpoints (Port 8200)

- `POST /api/scrape`: Submit a new scraping job
- `GET /api/job/{job_id}`: Check job status
- `POST /api/job/{job_id}/cancel`: Cancel a job

## ğŸ› ï¸ Configuration

Configuration is handled via the root `.env` file and `backend-common`.
